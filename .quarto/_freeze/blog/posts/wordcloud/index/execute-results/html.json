{
  "hash": "7535e65b13fa6da672b3f6871d1dc3f6",
  "result": {
    "markdown": "---\ntitle: A rudimentary wordcloud from twitter data\ncategories:\n  - R\n  - wordcloud\n  - rtweet\n  - tutorial\ndate: \"2022/09/17\"\n---\n\n\nIn this post I'll build a wordcloud from twitter texts. I'll be using the\namazing [rtweet][rtweet] package to access the [twitter API][twitterAPI]. At the\ntime of writing, rtweet can only acces the version 1 of the API, from which\nthere is possible to obtain a single table with the query results. Version 2\nallows for much more control on the query output but is not yet implemented in\nrtweet and I wanted to try it out ;)\n\nThe wordcloud is a powerfull way to visualize word frequencies in a text and\ngrasp something about the topics covered within. To build it we need a list of\nwords and the frequency for each of them. There is much more than it seems to\nthis, but as a first *naive* approximation one could just separate each document\ninto single words and build a table from that. This is exactly what this post\nwill cover.\n\n# Accessing twitter from R\n\nThe twitter API offers extensive functionality to query *tweets*, with different\nlevels of access according to your account type. For this exercise we only need\nthe most basic level, basically we want to download a certain ammount of\n*tweets* that match a *string*. This is the same thing as opening the app on\nyour phone and *searching* for a keyword. We don't need to register an app for\nthis (using v.1), and rtweet provides a handy function to authenticate the\n*currently logged-in user* and store the relevant info for future sessions.\nWe'll be using this method as this is a one-time query.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('rtweet')\n# Authenticate the currently logged-in user and store credentials, this needs to\n# be done only once per machine:\n# rtweet::auth_setup_default()\n\n# Do not perform query if results are already stored:\ntbl_file = 'tweets_tbl.rds'\ntweets_file = 'tweets.csv'\n\nif (file.exists(tweets_file)) {\n  tweets = read.csv(tweets_file)\n} else {\n  tweets = rtweet::search_tweets(\n    'chile -filter:quote -filter:media lang:es',\n    n = 2000,\n    include_rts = FALSE,\n    retryonratelimit = TRUE\n  )\n  # let's save the tibble just in case and write a csv ommiting list cols\n  saveRDS(tweets, tbl_file)\n  tweets = tweets[, sapply(tweets, class) != 'list'] |> as.data.frame()\n  write.csv(tweets, tweets_file, row.names = FALSE)\n}\n```\n:::\n\n\nLet's take a look at what we got:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(tweets, give.attr = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t2000 obs. of  37 variables:\n $ created_at                   : chr  \"2022-10-18 10:52:59\" \"2022-10-17 16:44:43\" \"2022-10-17 17:26:37\" \"2022-10-18 22:13:35\" ...\n $ id                           : num  1.58e+18 1.58e+18 1.58e+18 1.58e+18 1.58e+18 ...\n $ id_str                       : num  1.58e+18 1.58e+18 1.58e+18 1.58e+18 1.58e+18 ...\n $ full_text                    : chr  \"A tres a침os del #EstallidoDelictual el Presidente Boric no ha aprendido absolutamente nada. Fue c칩mplice de la \"| __truncated__ \"游댮 Banco Mundial advierte que pobreza en Chile llegar치 a 10,5% en 2022: La desigualdad tambi칠n aumentar치 https:\"| __truncated__ \"Walmart Chile remata locales y terrenos en distintas comunas de Santiago https://t.co/E1rbFfm8eD\" \"@danieljadue JADUE  TU Y TUS  REVOLUCIONARIOS. TERRORISTAS QUE MANDASTE A QUEMAR CHILE EERES UN MALDITO CON TU \"| __truncated__ ...\n $ truncated                    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ display_text_range           : int  279 127 96 163 139 320 43 169 56 122 ...\n $ source                       : chr  \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" \"<a href=\\\"https://www.echobox.com\\\" rel=\\\"nofollow\\\">Echobox</a>\" \"<a href=\\\"https://www.echobox.com\\\" rel=\\\"nofollow\\\">Echobox</a>\" \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\" ...\n $ in_reply_to_status_id        : num  NA NA NA 1.58e+18 1.58e+18 ...\n $ in_reply_to_status_id_str    : num  NA NA NA 1.58e+18 1.58e+18 ...\n $ in_reply_to_user_id          : num  NA NA NA 1.47e+08 5.80e+07 ...\n $ in_reply_to_user_id_str      : num  NA NA NA 1.47e+08 5.80e+07 ...\n $ in_reply_to_screen_name      : chr  NA NA NA \"danieljadue\" ...\n $ contributors                 : logi  NA NA NA NA NA NA ...\n $ is_quote_status              : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ retweet_count                : int  3472 1346 1976 0 0 0 0 0 0 0 ...\n $ favorite_count               : int  8787 1058 2209 0 0 0 0 0 0 0 ...\n $ favorited                    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ retweeted                    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ lang                         : chr  \"es\" \"es\" \"es\" \"es\" ...\n $ possibly_sensitive           : logi  NA FALSE FALSE NA NA NA ...\n $ text                         : chr  \"A tres a침os del #EstallidoDelictual el Presidente Boric no ha aprendido absolutamente nada. Fue c칩mplice de la \"| __truncated__ \"游댮 Banco Mundial advierte que pobreza en Chile llegar치 a 10,5% en 2022: La desigualdad tambi칠n aumentar치 https:\"| __truncated__ \"Walmart Chile remata locales y terrenos en distintas comunas de Santiago https://t.co/E1rbFfm8eD\" \"@danieljadue JADUE  TU Y TUS  REVOLUCIONARIOS. TERRORISTAS QUE MANDASTE A QUEMAR CHILE EERES UN MALDITO CON TU \"| __truncated__ ...\n $ favorited_by                 : logi  NA NA NA NA NA NA ...\n $ scopes                       : logi  NA NA NA NA NA NA ...\n $ display_text_width           : logi  NA NA NA NA NA NA ...\n $ retweeted_status             : logi  NA NA NA NA NA NA ...\n $ quoted_status_id             : logi  NA NA NA NA NA NA ...\n $ quoted_status_id_str         : logi  NA NA NA NA NA NA ...\n $ quoted_status_permalink      : logi  NA NA NA NA NA NA ...\n $ quote_count                  : logi  NA NA NA NA NA NA ...\n $ timestamp_ms                 : logi  NA NA NA NA NA NA ...\n $ reply_count                  : logi  NA NA NA NA NA NA ...\n $ filter_level                 : logi  NA NA NA NA NA NA ...\n $ query                        : logi  NA NA NA NA NA NA ...\n $ withheld_scope               : logi  NA NA NA NA NA NA ...\n $ withheld_copyright           : logi  NA NA NA NA NA NA ...\n $ withheld_in_countries        : logi  NA NA NA NA NA NA ...\n $ possibly_sensitive_appealable: logi  NA NA NA NA NA NA ...\n```\n:::\n:::\n\n\nLet's now have a look at a sample text. The most *retweeted* text is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(tweets, full_text[which.max(retweet_count)]) |>\n  strwrap() |>\n  cat(fill = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA tres a침os del #EstallidoDelictual el Presidente Boric no ha aprendido \nabsolutamente nada. Fue c칩mplice de la legitimaci칩n de la violencia y \nde la destrucci칩n de un Chile que es m치s pobre, inseguro y desigual que antes \n A pesar de eso, sigue enamorado de su fracasada revoluci칩n\n```\n:::\n:::\n\n\nThere's something here that is not a word but a *link*. This is rather common\nnowadays, text is mingled with *links*, *hashtags*, *mentions* and other things.\nThis will be a problem if we treat them as just another word. Let's create a\nsample text that has all of these things:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = 'Hola @persona, este mensaje no tiene otro objetivo que ayudarnos\na filtrar cosas que no son palabras. 3215. https://aquinoes.cl #aquitampoco'\n```\n:::\n\n\nWe can use this sample as a test case and see if we're able to get a word count\nfor *meaningful* words. If this was only regular text the task would reduce to\nsplitting by words, removing punctuation characters, adjusting capitalization\nand counting; but having these *things-that-are-not-a-word* we'll instead need to:\n\n1. split by words\n1. remove *links*\n1. remove *hashtags*\n1. remove *mentions* (e.g. `'@camara_cl'`)\n1. remove *punctuation* and other non alphabetic characters\n1. remove any *empty string* left\n\nLet's start by splitting:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstrsplit(tx, '[[:space:]]')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n [1] \"Hola\"                \"@persona,\"           \"este\"               \n [4] \"mensaje\"             \"no\"                  \"tiene\"              \n [7] \"otro\"                \"objetivo\"            \"que\"                \n[10] \"ayudarnos\"           \"a\"                   \"filtrar\"            \n[13] \"cosas\"               \"que\"                 \"no\"                 \n[16] \"son\"                 \"palabras.\"           \"3215.\"              \n[19] \"https://aquinoes.cl\" \"#aquitampoco\"       \n```\n:::\n:::\n\n\nNote that `strsplit()` returns a `list`. This will be the starting point when\nprocessing all the *tweets*, so for now we'll focus on the only element of this\nlist:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = strsplit(tx, '[[:space:]+]')[[1L]]\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Hola\"                \"@persona,\"           \"este\"               \n [4] \"mensaje\"             \"no\"                  \"tiene\"              \n [7] \"otro\"                \"objetivo\"            \"que\"                \n[10] \"ayudarnos\"           \"a\"                   \"filtrar\"            \n[13] \"cosas\"               \"que\"                 \"no\"                 \n[16] \"son\"                 \"palabras.\"           \"3215.\"              \n[19] \"https://aquinoes.cl\" \"#aquitampoco\"       \n```\n:::\n:::\n\n\nBefore we remove non alpha-numeric characters we'll want to get rid of *links*,\n*hashtags* and *mentions*, since these are defined by such characters. For\nconsistency we'll treat numbers also here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_link = function (x) grepl('^[[:lower:]]+://.+', x)\nis_hashtag = function (x) grepl('^#.+', x)\nis_mention = function (x) grepl('^@.+', x)\nis_number = function (x) grepl('^[[:digit:]]+[[:punct:]]*$', x)\n```\n:::\n\n\nLet's see if these work:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx[is_link(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"https://aquinoes.cl\"\n```\n:::\n\n```{.r .cell-code}\ntx[is_hashtag(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"#aquitampoco\"\n```\n:::\n\n```{.r .cell-code}\ntx[is_mention(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"@persona,\"\n```\n:::\n\n```{.r .cell-code}\ntx[is_number(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3215.\"\n```\n:::\n:::\n\n\nNailed it. Now it's easy to remove these things:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = tx[!is_link(tx)]\ntx = tx[!is_hashtag(tx)]\ntx = tx[!is_mention(tx)]\ntx = tx[!is_number(tx)]\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Hola\"      \"este\"      \"mensaje\"   \"no\"        \"tiene\"     \"otro\"     \n [7] \"objetivo\"  \"que\"       \"ayudarnos\" \"a\"         \"filtrar\"   \"cosas\"    \n[13] \"que\"       \"no\"        \"son\"       \"palabras.\"\n```\n:::\n:::\n\n\nThis looks good, now let's remove *punctuation* and anything that is not an\nalpha-numeric character:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = lapply(tx, gsub, pattern = '[^[:alnum:]]', replacement = '') |> unlist()\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Hola\"      \"este\"      \"mensaje\"   \"no\"        \"tiene\"     \"otro\"     \n [7] \"objetivo\"  \"que\"       \"ayudarnos\" \"a\"         \"filtrar\"   \"cosas\"    \n[13] \"que\"       \"no\"        \"son\"       \"palabras\" \n```\n:::\n:::\n\n\nFinally, let's filter out any empty strings and get everything to lower case:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = tx[tx != ''] |> tolower()\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"hola\"      \"este\"      \"mensaje\"   \"no\"        \"tiene\"     \"otro\"     \n [7] \"objetivo\"  \"que\"       \"ayudarnos\" \"a\"         \"filtrar\"   \"cosas\"    \n[13] \"que\"       \"no\"        \"son\"       \"palabras\" \n```\n:::\n:::\n\n\nSince we'll be doing this same procedure to every *tweet* the cleanest way would\nbe to pack it all into a function we can `apply` over the *tweets* vector:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_words = function (x) {\n  x = x[!is_link(x)]\n  x = x[!is_hashtag(x)]\n  x = x[!is_mention(x)]\n  x = x[!is_number(x)]\n  x = lapply(x, gsub, pattern = '[^[:alnum:]]', replacement = '') |> unlist()\n  x = x[x != '']\n  tolower(x)\n}\n```\n:::\n\n\nWith this function we can *cleanse* every tweet in a single call to `lapply`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets[['full_text']] |> strsplit(split = '[[:space:]]') |> lapply(extract_words) |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n [1] \"a\"             \"tres\"          \"a침os\"          \"del\"          \n [5] \"el\"            \"presidente\"    \"boric\"         \"no\"           \n [9] \"ha\"            \"aprendido\"     \"absolutamente\" \"nada\"         \n[13] \"fue\"           \"c칩mplice\"      \"de\"            \"la\"           \n[17] \"legitimaci칩n\"  \"de\"            \"la\"            \"violencia\"    \n[21] \"y\"             \"de\"            \"la\"            \"destrucci칩n\"  \n[25] \"de\"            \"un\"            \"chile\"         \"que\"          \n[29] \"es\"            \"m치s\"           \"pobre\"         \"inseguro\"     \n[33] \"y\"             \"desigual\"      \"que\"           \"antes\"        \n[37] \"a\"             \"pesar\"         \"de\"            \"eso\"          \n[41] \"sigue\"         \"enamorado\"     \"de\"            \"su\"           \n[45] \"fracasada\"     \"revoluci칩n\"   \n\n[[2]]\n [1] \"banco\"       \"mundial\"     \"advierte\"    \"que\"         \"pobreza\"    \n [6] \"en\"          \"chile\"       \"llegar치\"     \"a\"           \"105\"        \n[11] \"en\"          \"la\"          \"desigualdad\" \"tambi칠n\"     \"aumentar치\"  \n\n[[3]]\n [1] \"walmart\"   \"chile\"     \"remata\"    \"locales\"   \"y\"         \"terrenos\" \n [7] \"en\"        \"distintas\" \"comunas\"   \"de\"        \"santiago\" \n\n[[4]]\n [1] \"jadue\"           \"tu\"              \"y\"               \"tus\"            \n [5] \"revolucionarios\" \"terroristas\"     \"que\"             \"mandaste\"       \n [9] \"a\"               \"quemar\"          \"chile\"           \"eeres\"          \n[13] \"un\"              \"maldito\"         \"con\"             \"tu\"             \n[17] \"comunismo\"       \"andate\"          \"a\"               \"venezuela\"      \n[21] \"asqueroso\"       \"comunista\"      \n\n[[5]]\n [1] \"el\"          \"borrachito\"  \"fue\"         \"el\"          \"culpable\"   \n [6] \"de\"          \"la\"          \"divisi칩n\"    \"y\"           \"destrucci칩n\"\n[11] \"de\"          \"chile\"       \"no\"          \"merece\"      \"ningun\"     \n[16] \"mural\"      \n\n[[6]]\n [1] \"yo\"              \"he\"              \"estado\"          \"en\"             \n [5] \"varias\"          \"marchas\"         \"siempre\"         \"pac칤ficas\"      \n [9] \"y\"               \"muchas\"          \"multitudinarias\" \"de\"             \n[13] \"cientos\"         \"de\"              \"miles\"           \"no\"             \n[17] \"crees\"           \"qu칠\"             \"hay\"             \"algo\"           \n[21] \"err칩neo\"         \"en\"              \"algunas\"         \"causas\"         \n[25] \"que\"             \"se\"              \"promueven\"       \"que\"            \n[29] \"siempre\"         \"terminan\"        \"en\"              \"violencia\"      \n[33] \"o\"               \"que\"             \"nacen\"           \"de\"             \n[37] \"ella\"            \"a\"               \"veces\"           \"terroristas\"    \n[41] \"como\"            \"el\"              \"18o\"             \"no\"             \n[45] \"te\"              \"parece\"          \"raro\"           \n```\n:::\n:::\n\n\nNow we have a list of character vectors containing only words, but most of those\nword aren't *meaningful*. For this post we'll use a rough hack and just filter\nthose words that have between 5 and 10 characters. This will almost certainly\ncrop all short illatives such as *de*, *y*, *para*; but is by no means a proper\nway of ensuring we're left with all *meaninful* words (I'm sure *god* would\nagree that at the *end* the value of a *word* is not given by it's number of\ncharacters).  That said, let's get into it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_tweets = tweets[['full_text']] |>\n  strsplit(split = '[[:space:]+]') |>\n  lapply(extract_words)\n\nwords = lapply(clean_tweets, function (x) {\n  n = nchar(x)\n  x[n >= 5 & n <= 10]\n})\n\nword_bag = unlist(words)\n```\n:::\n\n\nLet's take a look at the 12 most frequent words:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(word_bag) |> sort(decreasing = TRUE) |> head(n = 13)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nword_bag\n     chile   gobierno      todos      boric     porque      ahora      tiene \n      1639        108         87         85         80         79         79 \n     hacer     cuando presidente      desde  estallido      gente \n        77         74         69         67         58         54 \n```\n:::\n:::\n\n\nThe most frequent word is the one we used for the query, which is to be expected\nand gives us no info about the topics being commented. We should by all means\nremove this word:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_bag = local({\n  query = 'chile'\n  word_bag[!(word_bag %in% query)]\n})\n```\n:::\n\n\nNow this is boring, since we're leaving out all semantic structure and treating\ntext as a *word bag* we should at least make it look beautiful. By far the most\ncompelling visualization for word fequencies is the *wordcloud*. We'll use the\n[wordcloud2][wordcloud2] package along the [wesanderson][wesanderson] color\npalettes to build one. Wordcloud's  main function expects a `data.frame` with\n`word` and `freq` as columns, so let's construct that from our *word bag* and\ngenerate a cloud:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('wordcloud2')\nlibrary('wesanderson')\n\nwf = local({\n  wb = table(word_bag)\n  word = names(wb)\n  freq = as.numeric(wb)\n  data.frame(word, freq)[freq >= 10, ]\n})\n\n# Nice colors from 'The Darjeeling Express'\nclrs = rep(wesanderson::wes_palette('Darjeeling1', 5), length.out = nrow(wf))\n\nwordcloud2::wordcloud2(wf,\n  background = 'transparent',\n  color = clrs,\n  size = .3)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-cdfefc2e997ef70f32c7\" style=\"width:100%;height:464px;\" class=\"wordcloud2 html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-cdfefc2e997ef70f32c7\">{\"x\":{\"word\":[\"acaba\",\"actual\",\"adem치s\",\"ahora\",\"alguien\",\"alg칰n\",\"algunas\",\"algunos\",\"amigo\",\"antes\",\"apoyo\",\"aragua\",\"argentina\",\"ayuda\",\"banco\",\"basura\",\"boric\",\"brasil\",\"buena\",\"buenas\",\"bueno\",\"cabeza\",\"calle\",\"cambiar\",\"cambio\",\"celebrar\",\"chileno\",\"chilenos\",\"cierto\",\"claro\",\"colombia\",\"comunismo\",\"comunista\",\"comunistas\",\"concierto\",\"congreso\",\"contra\",\"cosas\",\"creen\",\"creer\",\"crisis\",\"cualquier\",\"cuando\",\"cuenta\",\"culpa\",\"deben\",\"deber칤a\",\"decir\",\"dejar\",\"dejen\",\"demandas\",\"dem치s\",\"democracia\",\"derecha\",\"derecho\",\"derechos\",\"desde\",\"despu칠s\",\"destruir\",\"dicen\",\"donde\",\"durante\",\"ecuador\",\"educaci칩n\",\"ejemplo\",\"ellos\",\"empresas\",\"entonces\",\"entrada\",\"entre\",\"escuchar\",\"esperanza\",\"estaba\",\"estado\",\"estafan\",\"estallido\",\"estamos\",\"est치n\",\"estar\",\"estas\",\"est치s\",\"estos\",\"estoy\",\"existe\",\"extrema\",\"f치cil\",\"falabella\",\"falta\",\"familia\",\"favor\",\"fecha\",\"fern치ndez\",\"forma\",\"fuera\",\"fueron\",\"fuerza\",\"gabriel\",\"ganas\",\"gente\",\"gobierno\",\"gracias\",\"grande\",\"guerra\",\"gusta\",\"haber\",\"hablar\",\"hacen\",\"hacer\",\"haciendo\",\"hagan\",\"hasta\",\"hecho\",\"hicieron\",\"historia\",\"igual\",\"importa\",\"impuestos\",\"impunidad\",\"inflaci칩n\",\"izquierda\",\"jam치s\",\"junto\",\"justicia\",\"justo\",\"libertad\",\"libre\",\"llegar\",\"lleg칩\",\"llorar\",\"luego\",\"malestar\",\"ma침ana\",\"manos\",\"mayor칤a\",\"medio\",\"medios\",\"mejor\",\"menos\",\"mentiras\",\"merluzo\",\"meses\",\"metro\",\"m칠xico\",\"miedo\",\"mientras\",\"mierda\",\"miles\",\"millones\",\"misma\",\"mismo\",\"mismos\",\"momento\",\"mucha\",\"muchas\",\"mucho\",\"muchos\",\"mujer\",\"mundial\",\"mundo\",\"nacional\",\"nadie\",\"necesita\",\"negro\",\"ning칰n\",\"nivel\",\"noticias\",\"nuestra\",\"nuestro\",\"nuestros\",\"nueva\",\"nuevo\",\"nunca\",\"octubre\",\"octubrismo\",\"orden\",\"otras\",\"otros\",\"pablo\",\"pagar\",\"pa칤ses\",\"parece\",\"parte\",\"partido\",\"pasado\",\"pasaporte\",\"pedir\",\"pensar\",\"persona\",\"personas\",\"pi침era\",\"plata\",\"pobre\",\"pobreza\",\"poder\",\"podr칤a\",\"polic칤as\",\"pol칤tica\",\"pol칤ticos\",\"poner\",\"porque\",\"posible\",\"presidente\",\"primer\",\"primera\",\"problema\",\"problemas\",\"pronto\",\"pueblo\",\"puede\",\"pueden\",\"puedo\",\"queda\",\"quemar\",\"quemaron\",\"queremos\",\"quien\",\"quienes\",\"quiere\",\"quieren\",\"quiero\",\"realidad\",\"rechazo\",\"reforma\",\"regi칩n\",\"respuesta\",\"sabemos\",\"saber\",\"sacar\",\"sali칩\",\"salir\",\"salud\",\"saludos\",\"santiago\",\"seguir\",\"seguridad\",\"se침or\",\"ser칤a\",\"servicio\",\"siempre\",\"siendo\",\"sigue\",\"siguen\",\"sistema\",\"sobre\",\"social\",\"sociales\",\"somos\",\"tambi칠n\",\"tanta\",\"tanto\",\"tardes\",\"taylor\",\"tenemos\",\"tener\",\"tenga\",\"tengo\",\"terrorismo\",\"tiempo\",\"tiendas\",\"tiene\",\"tienen\",\"tienes\",\"tierra\",\"todas\",\"todos\",\"trabajar\",\"trabajo\",\"trav칠s\",\"칰nico\",\"uruguay\",\"usted\",\"ustedes\",\"vamos\",\"veces\",\"venezuela\",\"venga\",\"venir\",\"verdad\",\"viene\",\"violencia\",\"vivir\"],\"freq\":[14,13,11,79,23,11,11,17,10,35,15,11,45,12,11,10,85,14,14,15,25,10,12,10,12,19,17,46,14,20,36,26,23,34,13,12,28,20,15,15,16,16,74,22,18,20,12,32,13,11,10,13,17,49,11,11,67,21,19,14,46,13,11,11,12,42,15,14,10,22,12,11,27,30,10,58,31,49,26,20,11,31,30,13,11,10,15,18,12,29,16,10,12,20,24,21,12,12,54,108,42,29,11,14,12,14,28,77,12,10,46,19,16,40,37,16,14,10,12,50,14,10,19,11,17,14,13,11,11,18,13,27,16,14,21,16,52,46,11,10,14,10,17,14,17,23,10,17,11,49,12,18,10,14,27,20,10,18,34,17,39,14,14,20,17,11,16,26,11,23,18,47,30,12,14,10,30,11,11,31,18,33,14,18,11,12,15,17,25,45,19,14,26,43,12,10,24,19,10,80,14,69,13,29,41,24,11,27,41,19,22,11,11,17,14,25,15,27,36,26,15,17,10,11,11,12,15,12,10,12,12,17,20,15,13,10,14,15,46,22,23,27,16,29,42,14,21,46,12,27,14,24,34,24,11,31,12,20,13,79,51,20,10,21,87,11,19,17,14,11,19,38,26,15,27,13,12,30,17,42,16],\"fontFamily\":\"Segoe UI\",\"fontWeight\":\"bold\",\"color\":[\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\"],\"minSize\":0,\"weightFactor\":0.5,\"backgroundColor\":\"transparent\",\"gridSize\":0,\"minRotation\":-0.785398163397448,\"maxRotation\":0.785398163397448,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":{\"render\":[{\"code\":\"function(el,x){\\n                        console.log(123);\\n                        if(!iii){\\n                          window.location.reload();\\n                          iii = False;\\n\\n                        }\\n  }\",\"data\":null}]}}</script>\n```\n:::\n:::\n\n\n## Write a summary and conclusion here\n\n\n\n\n\n---\n\n\n::: {.cell filename='Complete Code' file='script.r'}\n\n```{.r .cell-code}\n## ----r------------------------------------------------------------------------\nlibrary('rtweet')\n# Authenticate the currently logged-in user and store credentials, this needs to\n# be done only once per machine:\n# rtweet::auth_setup_default()\n\n# Do not perform query if results are already stored:\ntbl_file = 'tweets_tbl.rds'\ntweets_file = 'tweets.csv'\n\nif (file.exists(tweets_file)) {\n  tweets = read.csv(tweets_file)\n} else {\n  tweets = rtweet::search_tweets(\n    'chile -filter:quote -filter:media lang:es',\n    n = 2000,\n    include_rts = FALSE,\n    retryonratelimit = TRUE\n  )\n  # let's save the tibble just in case and write a csv ommiting list cols\n  saveRDS(tweets, tbl_file)\n  tweets = tweets[, sapply(tweets, class) != 'list'] |> as.data.frame()\n  write.csv(tweets, tweets_file, row.names = FALSE)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n## ----r------------------------------------------------------------------------\nis_link = function (x) grepl('^[[:lower:]]+://.+', x)\nis_hashtag = function (x) grepl('^#.+', x)\nis_mention = function (x) grepl('^@.+', x)\nis_number = function (x) grepl('^[[:digit:]]+[[:punct:]]*$', x)\n\n\n\n\n\n\n\n\n\n\n## ----r------------------------------------------------------------------------\nextract_words = function (x) {\n  x = x[!is_link(x)]\n  x = x[!is_hashtag(x)]\n  x = x[!is_mention(x)]\n  x = x[!is_number(x)]\n  x = lapply(x, gsub, pattern = '[^[:alnum:]]', replacement = '') |> unlist()\n  x = x[x != '']\n  tolower(x)\n}\n\n\n\n\n## ----r------------------------------------------------------------------------\nclean_tweets = tweets[['full_text']] |>\n  strsplit(split = '[[:space:]+]') |>\n  lapply(extract_words)\n\nwords = lapply(clean_tweets, function (x) {\n  n = nchar(x)\n  x[n >= 5 & n <= 10]\n})\n\nword_bag = unlist(words)\n\n\n\n\n## ----r------------------------------------------------------------------------\nword_bag = local({\n  query = 'chile'\n  word_bag[!(word_bag %in% query)]\n})\n\n\n## ----r------------------------------------------------------------------------\nlibrary('wordcloud2')\nlibrary('wesanderson')\n\nwf = local({\n  wb = table(word_bag)\n  word = names(wb)\n  freq = as.numeric(wb)\n  data.frame(word, freq)[freq >= 10, ]\n})\n\n# Nice colors from 'The Darjeeling Express'\nclrs = rep(wesanderson::wes_palette('Darjeeling1', 5), length.out = nrow(wf))\n\nwordcloud2::wordcloud2(wf,\n  background = 'transparent',\n  color = clrs,\n  size = .3)\n```\n:::\n\n\n[wordcloud2]: https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html\n[twitterAPI]: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjiqurGgOj6AhWdDLkGHfjBBRcQFnoECA8QAQ&url=https%3A%2F%2Fdeveloper.twitter.com%2Fen%2Fdocs%2Ftwitter-api&usg=AOvVaw07KoWHf5ew9enXbRwVd6eq\n[rtweet]: https://github.com/ropensci/rtweet\n[wesanderson]: https://github.com/karthik/wesanderson\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<link href=\"../../../site_libs/wordcloud2-0.0.1/wordcloud.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/wordcloud2-0.0.1/wordcloud2-all.js\"></script>\n<script src=\"../../../site_libs/wordcloud2-0.0.1/hover.js\"></script>\n<script src=\"../../../site_libs/wordcloud2-binding-0.2.1/wordcloud2.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}