{
  "hash": "e64d4fd1bf4f72413166c9f80e319b64",
  "result": {
    "markdown": "---\ntitle: A rudimentary wordcloud from twitter data\ncategories:\n  - R\n  - wordcloud\n  - rtweet\n  - TPP11\n  - tutorial\ndate: \"2022/09/17\"\n---\n\n\nLast week the [Comprehensive and Progressive Agreement for Trans-Pacific\nPartnership][tpp11] (CPTPP; *aka* TPP11) was approved by the chilean\ncongress. \n\nLet's try to get an idea of what people are saying about this on twitter. We'll\nbe using the [twitter API][twitterAPI] through the [rtweet][rtweet] package to\naccess *tweets* directly from R.\n\n# Accessing twitter from R\n\nThe twitter API offers extensive functionality to query *tweets*, with different\nlevels of access according to your account type. For this exercise we only need\nthe most basic level, basically we want to download a certain ammount of\n*tweets* that match a *string*. This is the same thing as opening the app on\nyour phone and *searching* for a keyword. We don't need to register an app for\nthis, and rtweet provides a handy function to authenticate the *currently\nlogged-in user* and store the relevant info for future sessions. We'll be using\nthis method as this is a one-time query.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('rtweet')\n# Authenticate the currently logged-in user and store credentials, this needs to\n# be done only once per machine:\n# rtweet::auth_setup_default()\n\n# Do not perform query if results are already stored:\ntbl_file = 'tweets_tbl.rds'\ntweets_file = 'tpp11_tweets.csv'\n\nif (file.exists(tweets_file)) {\n  tweets = read.csv(tweets_file)\n} else {\n  tweets = rtweet::search_tweets(\n    'TPP11 Chile -filter:quote -filter:replies',\n    n = 1000,\n    include_rts = FALSE,\n    retryonratelimit = TRUE\n  )\n  # let's save the tibble just in case and write a csv ommiting list cols\n  saveRDS(tweets, tbl_file)\n  tweets = tweets[, sapply(tweets, class) != 'list'] |> as.data.frame()\n  write.csv(tweets, tweets_file, row.names = FALSE)\n}\n```\n:::\n\n\nLet's take a look at what we got:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(tweets, give.attr = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t643 obs. of  36 variables:\n $ created_at                   : chr  \"2022-10-12 14:09:24\" \"2022-10-12 16:19:04\" \"2022-10-11 19:45:39\" \"2022-10-12 18:53:52\" ...\n $ id                           : num  1.58e+18 1.58e+18 1.58e+18 1.58e+18 1.58e+18 ...\n $ id_str                       : num  1.58e+18 1.58e+18 1.58e+18 1.58e+18 1.58e+18 ...\n $ full_text                    : chr  \"‚ÄúSide Letters‚Äù: autogol d media cancha d Pdte @gabrielboric . Si aprueba TPP11, pierde ante su base radical; si\"| __truncated__ \"Bancada UDI pone en duda agenda legislativa y di√°logo constitucional si Gobierno dilata TPP11  https://t.co/NQcBH1SVjc\" \"üî¥ Aprueban TPP11: Senado ratifica adhesi√≥n de Chile al tratado https://t.co/o61z5in3oR\" \"Sres. @Chile_Vamos_ @udipopular @RNchile @evopoli @PRChile @ChilePDGcl .Muchos de Chile Vamos \\\" CORRIERON\\\" a \"| __truncated__ ...\n $ truncated                    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ display_text_range           : int  263 118 86 280 278 115 272 66 253 279 ...\n $ source                       : chr  \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" \"<a href=\\\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\\\" rel=\\\"nofollow\\\">Autopublicado\"| __truncated__ \"<a href=\\\"https://www.echobox.com\\\" rel=\\\"nofollow\\\">Echobox</a>\" \"<a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web App</a>\" ...\n $ in_reply_to_status_id        : logi  NA NA NA NA NA NA ...\n $ in_reply_to_status_id_str    : logi  NA NA NA NA NA NA ...\n $ in_reply_to_user_id          : logi  NA NA NA NA NA NA ...\n $ in_reply_to_user_id_str      : logi  NA NA NA NA NA NA ...\n $ in_reply_to_screen_name      : logi  NA NA NA NA NA NA ...\n $ contributors                 : logi  NA NA NA NA NA NA ...\n $ is_quote_status              : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ retweet_count                : int  422 164 54 0 1 0 0 3 0 0 ...\n $ favorite_count               : int  747 543 335 0 2 0 1 2 0 2 ...\n $ favorited                    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ retweeted                    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ lang                         : chr  \"es\" \"es\" \"es\" \"es\" ...\n $ text                         : chr  \"‚ÄúSide Letters‚Äù: autogol d media cancha d Pdte @gabrielboric . Si aprueba TPP11, pierde ante su base radical; si\"| __truncated__ \"Bancada UDI pone en duda agenda legislativa y di√°logo constitucional si Gobierno dilata TPP11  https://t.co/NQcBH1SVjc\" \"üî¥ Aprueban TPP11: Senado ratifica adhesi√≥n de Chile al tratado https://t.co/o61z5in3oR\" \"Sres. @Chile_Vamos_ @udipopular @RNchile @evopoli @PRChile @ChilePDGcl .Muchos de Chile Vamos \\\" CORRIERON\\\" a \"| __truncated__ ...\n $ favorited_by                 : logi  NA NA NA NA NA NA ...\n $ scopes                       : logi  NA NA NA NA NA NA ...\n $ display_text_width           : logi  NA NA NA NA NA NA ...\n $ retweeted_status             : logi  NA NA NA NA NA NA ...\n $ quoted_status_id             : logi  NA NA NA NA NA NA ...\n $ quoted_status_id_str         : logi  NA NA NA NA NA NA ...\n $ quoted_status_permalink      : logi  NA NA NA NA NA NA ...\n $ quote_count                  : logi  NA NA NA NA NA NA ...\n $ timestamp_ms                 : logi  NA NA NA NA NA NA ...\n $ reply_count                  : logi  NA NA NA NA NA NA ...\n $ filter_level                 : logi  NA NA NA NA NA NA ...\n $ query                        : logi  NA NA NA NA NA NA ...\n $ withheld_scope               : logi  NA NA NA NA NA NA ...\n $ withheld_copyright           : logi  NA NA NA NA NA NA ...\n $ withheld_in_countries        : logi  NA NA NA NA NA NA ...\n $ possibly_sensitive_appealable: logi  NA NA NA NA NA NA ...\n```\n:::\n:::\n\n\nThe most *retweeted* text (presumably the original) is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(tweets, full_text[which.max(retweet_count)]) |>\n  strwrap() |>\n  cat(fill = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAPROBADO‚úÖ| Senado aprob√≥ por 27 votos a favor, 10 en contra y 1 \nabstenci√≥n, el Tratado Integral y Progresista de Asociaci√≥n \nTranspac√≠fico, conocido como #TPP11.  \nEl proyecto de acuerdo pasa a la @camara_cl para comunicarle al \nEjecutivo la aprobaci√≥n del Congreso Nacional. ‚ñ∂ https://t.co/tGKC7XPDB2\n```\n:::\n:::\n\n\nWe can use this *tweet* as a test case and see if we're able to get a word count\nfor *meaningful* words. If this was only regular text the task would reduce to\nsplitting by words, removing punctuation characters, adjusting capitalization\nand counting; but there are a bunch of *things-that-are-not-a-word* in use\nnowadays. Based on this example, we need to:\n\n1. split by words\n1. remove *links*\n1. remove *hashtags*\n1. remove *mentions* (e.g. `'@camara_cl'`)\n1. remove *punctuation* and other non alphabetic characters\n1. remove any *empty string* left\n\nLet's start by splitting:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = with(tweets, full_text[which.max(retweet_count)])\nstrsplit(tx, '[[:space:]]')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n [1] \"APROBADO‚úÖ|\"             \"Senado\"                 \n [3] \"aprob√≥\"                  \"por\"                    \n [5] \"27\"                      \"votos\"                  \n [7] \"a\"                       \"favor,\"                 \n [9] \"10\"                      \"en\"                     \n[11] \"contra\"                  \"y\"                      \n[13] \"1\"                       \"abstenci√≥n,\"            \n[15] \"el\"                      \"Tratado\"                \n[17] \"Integral\"                \"y\"                      \n[19] \"Progresista\"             \"de\"                     \n[21] \"Asociaci√≥n\"              \"Transpac√≠fico,\"         \n[23] \"conocido\"                \"como\"                   \n[25] \"#TPP11.\"                 \"\"                       \n[27] \"El\"                      \"proyecto\"               \n[29] \"de\"                      \"acuerdo\"                \n[31] \"pasa\"                    \"a\"                      \n[33] \"la\"                      \"@camara_cl\"             \n[35] \"para\"                    \"comunicarle\"            \n[37] \"al\"                      \"Ejecutivo\"              \n[39] \"la\"                      \"aprobaci√≥n\"             \n[41] \"del\"                     \"Congreso\"               \n[43] \"Nacional.\"               \"‚ñ∂\"                      \n[45] \"https://t.co/tGKC7XPDB2\"\n```\n:::\n:::\n\n\nNote that `strsplit()` returns a `list`. This will be the starting point when\nprocessing all the *tweets*, so for now we'll focus on the only element of this\nlist:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = strsplit(tx, '[[:space:]+]')[[1L]]\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"APROBADO‚úÖ|\"             \"Senado\"                 \n [3] \"aprob√≥\"                  \"por\"                    \n [5] \"27\"                      \"votos\"                  \n [7] \"a\"                       \"favor,\"                 \n [9] \"10\"                      \"en\"                     \n[11] \"contra\"                  \"y\"                      \n[13] \"1\"                       \"abstenci√≥n,\"            \n[15] \"el\"                      \"Tratado\"                \n[17] \"Integral\"                \"y\"                      \n[19] \"Progresista\"             \"de\"                     \n[21] \"Asociaci√≥n\"              \"Transpac√≠fico,\"         \n[23] \"conocido\"                \"como\"                   \n[25] \"#TPP11.\"                 \"\"                       \n[27] \"El\"                      \"proyecto\"               \n[29] \"de\"                      \"acuerdo\"                \n[31] \"pasa\"                    \"a\"                      \n[33] \"la\"                      \"@camara_cl\"             \n[35] \"para\"                    \"comunicarle\"            \n[37] \"al\"                      \"Ejecutivo\"              \n[39] \"la\"                      \"aprobaci√≥n\"             \n[41] \"del\"                     \"Congreso\"               \n[43] \"Nacional.\"               \"‚ñ∂\"                      \n[45] \"https://t.co/tGKC7XPDB2\"\n```\n:::\n:::\n\n\nBefore we remove non alpha-numeric characters we'll want to get rid of *links*,\n*hashtags* and *mentions*, since these are defined by such characters. For\nconsistency we'll treat numbers also here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_link = function (x) grepl('^[[:lower:]]+://.+', x)\nis_hashtag = function (x) grepl('^#.+', x)\nis_mention = function (x) grepl('^@.+', x)\nis_number = function (x) grepl('^[[:digit:]]+$', x)\n```\n:::\n\n\nLet's see if these work:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx[is_link(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"https://t.co/tGKC7XPDB2\"\n```\n:::\n\n```{.r .cell-code}\ntx[is_hashtag(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"#TPP11.\"\n```\n:::\n\n```{.r .cell-code}\ntx[is_mention(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"@camara_cl\"\n```\n:::\n\n```{.r .cell-code}\ntx[is_number(tx)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"27\" \"10\" \"1\" \n```\n:::\n:::\n\n\nNailed it. Now it's easy to remove these things:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = tx[!is_link(tx)]\ntx = tx[!is_hashtag(tx)]\ntx = tx[!is_mention(tx)]\ntx = tx[!is_number(tx)]\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"APROBADO‚úÖ|\"    \"Senado\"         \"aprob√≥\"         \"por\"           \n [5] \"votos\"          \"a\"              \"favor,\"         \"en\"            \n [9] \"contra\"         \"y\"              \"abstenci√≥n,\"    \"el\"            \n[13] \"Tratado\"        \"Integral\"       \"y\"              \"Progresista\"   \n[17] \"de\"             \"Asociaci√≥n\"     \"Transpac√≠fico,\" \"conocido\"      \n[21] \"como\"           \"\"               \"El\"             \"proyecto\"      \n[25] \"de\"             \"acuerdo\"        \"pasa\"           \"a\"             \n[29] \"la\"             \"para\"           \"comunicarle\"    \"al\"            \n[33] \"Ejecutivo\"      \"la\"             \"aprobaci√≥n\"     \"del\"           \n[37] \"Congreso\"       \"Nacional.\"      \"‚ñ∂\"             \n```\n:::\n:::\n\n\nThis looks good, now let's remove *punctuation* and anything that is not an\nalpha-numeric character:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = lapply(tx, gsub, pattern = '[^[:alnum:]]', replacement = '') |> unlist()\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"APROBADO\"      \"Senado\"        \"aprob√≥\"        \"por\"          \n [5] \"votos\"         \"a\"             \"favor\"         \"en\"           \n [9] \"contra\"        \"y\"             \"abstenci√≥n\"    \"el\"           \n[13] \"Tratado\"       \"Integral\"      \"y\"             \"Progresista\"  \n[17] \"de\"            \"Asociaci√≥n\"    \"Transpac√≠fico\" \"conocido\"     \n[21] \"como\"          \"\"              \"El\"            \"proyecto\"     \n[25] \"de\"            \"acuerdo\"       \"pasa\"          \"a\"            \n[29] \"la\"            \"para\"          \"comunicarle\"   \"al\"           \n[33] \"Ejecutivo\"     \"la\"            \"aprobaci√≥n\"    \"del\"          \n[37] \"Congreso\"      \"Nacional\"      \"\"             \n```\n:::\n:::\n\n\nFinally, let's filter out those empty strings and get everything to lower case:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntx = tx[tx != ''] |> tolower()\ntx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"aprobado\"      \"senado\"        \"aprob√≥\"        \"por\"          \n [5] \"votos\"         \"a\"             \"favor\"         \"en\"           \n [9] \"contra\"        \"y\"             \"abstenci√≥n\"    \"el\"           \n[13] \"tratado\"       \"integral\"      \"y\"             \"progresista\"  \n[17] \"de\"            \"asociaci√≥n\"    \"transpac√≠fico\" \"conocido\"     \n[21] \"como\"          \"el\"            \"proyecto\"      \"de\"           \n[25] \"acuerdo\"       \"pasa\"          \"a\"             \"la\"           \n[29] \"para\"          \"comunicarle\"   \"al\"            \"ejecutivo\"    \n[33] \"la\"            \"aprobaci√≥n\"    \"del\"           \"congreso\"     \n[37] \"nacional\"     \n```\n:::\n:::\n\n\nSince we'll be doing this same procedure to every *tweet* the cleanest way would\nbe to pack it all into a function we can `apply` over the *tweets* vector:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_words = function (x) {\n  x = x[!is_link(x)]\n  x = x[!is_hashtag(x)]\n  x = x[!is_mention(x)]\n  x = x[!is_number(x)]\n  x = lapply(x, gsub, pattern = '[^[:alnum:]]', replacement = '') |> unlist()\n  x = x[x != '']\n  tolower(x)\n}\n```\n:::\n\n\nWith this function we can *cleanse* every tweet in a single call to `lapply`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets[['full_text']] |> strsplit(split = '[[:space:]]') |> lapply(extract_words) |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n [1] \"side\"      \"letters\"   \"autogol\"   \"d\"         \"media\"     \"cancha\"   \n [7] \"d\"         \"pdte\"      \"si\"        \"aprueba\"   \"tpp11\"     \"pierde\"   \n[13] \"ante\"      \"su\"        \"base\"      \"radical\"   \"si\"        \"rechaza\"  \n[19] \"pierde\"    \"ante\"      \"el\"        \"pa√≠s\"      \"si\"        \"sigue\"    \n[25] \"dilatando\" \"para\"      \"quedar\"    \"bien\"      \"con\"       \"todos\"    \n[31] \"pierde\"    \"ante\"      \"su\"        \"base\"      \"radical\"   \"el\"       \n[37] \"pa√≠s\"      \"y\"         \"los\"       \"socios\"    \"del\"       \"tpp11\"    \n\n[[2]]\n [1] \"bancada\"        \"udi\"            \"pone\"           \"en\"            \n [5] \"duda\"           \"agenda\"         \"legislativa\"    \"y\"             \n [9] \"di√°logo\"        \"constitucional\" \"si\"             \"gobierno\"      \n[13] \"dilata\"         \"tpp11\"         \n\n[[3]]\n[1] \"aprueban\" \"tpp11\"    \"senado\"   \"ratifica\" \"adhesi√≥n\" \"de\"       \"chile\"   \n[8] \"al\"       \"tratado\" \n\n[[4]]\n [1] \"sres\"             \"muchos\"           \"de\"               \"chile\"           \n [5] \"vamos\"            \"corrieron\"        \"a\"                \"la\"              \n [9] \"moneda\"           \"para\"             \"garantizarle\"     \"a\"               \n[13] \"una\"              \"nueva\"            \"constituci√≥npero\" \"le\"              \n[17] \"ha\"               \"hecho\"            \"la\"               \"tremenda\"        \n[21] \"tapa\"             \"al\"               \"tpp11c√≥mo\"        \"permiten\"        \n[25] \"tanta\"            \"humillaci√≥n\"     \n\n[[5]]\n [1] \"mientras\"     \"que\"          \"el\"           \"fmi\"          \"advierte\"    \n [6] \"del\"          \"desastre\"     \"que\"          \"se\"           \"viene\"       \n[11] \"para\"         \"chile\"        \"en\"           \"materia\"      \"econ√≥mica\"   \n[16] \"los\"          \"infradotados\" \"siguen\"       \"pidiendo\"     \"que\"         \n[21] \"boric\"        \"no\"           \"firme\"        \"el\"           \"secta\"       \n[26] \"qla\"          \"delirante\"    \"la\"           \"del\"          \"delfina\"     \n[31] \"guzm√°n\"       \"pancho\"       \"malo\"         \"bassa\"        \"talca\"       \n[36] \"camila\"       \"vallejo\"      \"karen\"        \"poniachik\"   \n\n[[6]]\n [1] \"la\"           \"verdad\"       \"del\"          \"tpp11\"        \"por\"         \n [6] \"favor\"        \"ver\"          \"y\"            \"enterarse\"    \"del\"         \n[11] \"desastre\"     \"de\"           \"lo\"           \"q\"            \"significar√≠a\"\n[16] \"para\"         \"chile\"       \n```\n:::\n:::\n\n\nNow we have a list of character vectors containing only words, but most of those\nword aren't *meaningful*. For this post we'll use a rough hack and just filter\nthose words that have between 5 and 10 characters. This will almost certainly\ncrop all short illatives such as *de*, *y*, *para*; but is by no means a proper\nway of ensuring we're left with all *meaninful* words (I'm sure *god* would\nagree that at the *end* the value of a *word* is not given by it's number of\ncharacters).  That said, let's get into it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_tweets = tweets[['full_text']] |>\n  strsplit(split = '[[:space:]+]') |>\n  lapply(extract_words)\n\nwords = lapply(clean_tweets, function (x) {\n  n = nchar(x)\n  x[n >= 5 & n <= 10]\n})\n\nword_bag = unlist(words)\n```\n:::\n\n\nLet's take a look at the 12 most frequent words:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(word_bag) |> sort(decreasing = TRUE) |> head(n = 13)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nword_bag\n     chile      tpp11     senado    tratado presidente      boric   gobierno \n       481        440        155         85         84         79         60 \n soberan√≠a   votaci√≥n      mejor     contra      sobre    aprueba \n        57         49         44         37         36         34 \n```\n:::\n:::\n\n\nThe two most frequent words are those we used for the query, which is to be\nexpected and gives us no info about the topics being commented. We should by all\nmeans remove this two words:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_bag = local({\n  query = c('tpp11', 'chile')\n  word_bag[!(word_bag %in% query)]\n})\n```\n:::\n\n\nNow this is boring, since we're leaving out all semantic structure and treating\ntext as a *word bag* we should at least make it look beautiful. By far the most\ncompelling visualization for word fequencies is the *wordcloud*. We'll use the\n[wordcloud2][wordcloud2] package along the [wesanderson][wesanderson] color\npalettesto build one. Wordcloud's  main function expects a `data.frame` with\n`word` and `freq` as columns, so let's construct that from our *word bag* and\ngenerate a cloud:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('wordcloud2')\nlibrary('wesanderson')\n\nwf = local({\n  wb = table(word_bag)\n  word = names(wb)\n  freq = as.numeric(wb)\n  data.frame(word, freq)[freq >= 10, ]\n})\n\n# Nice colors from 'The Darjeeling Express'\nclrs = rep(wesanderson::wes_palette('Darjeeling1', 5), length.out = nrow(wf))\n\nwordcloud2::wordcloud2(wf,\n  background = 'transparent',\n  color = clrs)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-d17171fb5a1d79823a0f\" style=\"width:100%;height:464px;\" class=\"wordcloud2 html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-d17171fb5a1d79823a0f\">{\"x\":{\"word\":[\"acuerdo\",\"adem√°s\",\"adhesi√≥n\",\"agenda\",\"ahora\",\"ahumada\",\"aprobaci√≥n\",\"aprobado\",\"aprobar\",\"aprob√≥\",\"aprueba\",\"arturo\",\"asociaci√≥n\",\"boric\",\"brunei\",\"bueno\",\"carta\",\"chilenos\",\"comercial\",\"comercio\",\"congreso\",\"conocido\",\"contra\",\"cptpp\",\"cuando\",\"dance\",\"delfina\",\"derecha\",\"derecho\",\"derechos\",\"derrota\",\"desarrollo\",\"desde\",\"dicen\",\"econom√≠a\",\"econ√≥mica\",\"econ√≥mico\",\"ellos\",\"empresas\",\"entre\",\"estado\",\"estamos\",\"estan\",\"est√°n\",\"esteban\",\"estos\",\"evitarle\",\"favor\",\"frenar\",\"frente\",\"gobierno\",\"grandes\",\"guzman\",\"hacer\",\"hasta\",\"historia\",\"ingreso\",\"integral\",\"intereses\",\"jaque\",\"karen\",\"karol\",\"laborales\",\"letters\",\"libre\",\"manos\",\"martes\",\"mejor\",\"metro\",\"mientras\",\"moneda\",\"mundo\",\"nacional\",\"necesita\",\"nuestra\",\"nuestro\",\"nueva\",\"octubre\",\"otros\",\"pa√≠ses\",\"parte\",\"pierde\",\"poder\",\"podr√≠a\",\"pol√≠tica\",\"poniachik\",\"porque\",\"presidente\",\"proceso\",\"programa\",\"proyecto\",\"pueblo\",\"puede\",\"quiere\",\"radio\",\"ratificar\",\"rechazo\",\"retirar\",\"retire\",\"revisa\",\"schalper\",\"semillas\",\"senado\",\"senador\",\"senadores\",\"siempre\",\"sigue\",\"silva\",\"sirve\",\"soberan√≠a\",\"sobre\",\"sociales\",\"subordina\",\"temas\",\"tenemos\",\"tiene\",\"todav√≠a\",\"todos\",\"tratado\",\"tratados\",\"√∫nico\",\"usted\",\"vidal\",\"video\",\"votaci√≥n\",\"votar√°\",\"votos\"],\"freq\":[31,10,16,10,27,20,33,18,25,13,34,18,11,79,13,11,11,11,10,10,15,10,37,11,12,13,18,18,10,19,10,23,19,10,13,27,13,17,17,17,29,15,12,21,18,13,13,34,11,13,60,16,13,19,21,12,10,12,18,11,18,14,13,19,12,32,20,44,16,13,15,15,23,11,18,16,11,15,11,24,15,12,12,11,19,18,16,84,11,11,26,19,14,15,10,14,11,29,30,15,14,18,155,18,18,14,11,17,12,57,36,17,12,10,10,25,11,16,85,11,10,10,18,15,49,10,16],\"fontFamily\":\"Segoe UI\",\"fontWeight\":\"bold\",\"color\":[\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\",\"#F2AD00\",\"#F98400\",\"#5BBCD6\",\"#FF0000\",\"#00A08A\"],\"minSize\":0,\"weightFactor\":1.16129032258065,\"backgroundColor\":\"transparent\",\"gridSize\":0,\"minRotation\":-0.785398163397448,\"maxRotation\":0.785398163397448,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":{\"render\":[{\"code\":\"function(el,x){\\n                        console.log(123);\\n                        if(!iii){\\n                          window.location.reload();\\n                          iii = False;\\n\\n                        }\\n  }\",\"data\":null}]}}</script>\n```\n:::\n:::\n\n\n## Write a summary and conclusion here\n\n\n\n\n\n---\n\n\n::: {.cell filename='Complete Code' file='script.r'}\n\n```{.r .cell-code}\n## ----r------------------------------------------------------------------------\nlibrary('rtweet')\n# Authenticate the currently logged-in user and store credentials, this needs to\n# be done only once per machine:\n# rtweet::auth_setup_default()\n\n# Do not perform query if results are already stored:\ntbl_file = 'tweets_tbl.rds'\ntweets_file = 'tpp11_tweets.csv'\n\nif (file.exists(tweets_file)) {\n  tweets = read.csv(tweets_file)\n} else {\n  tweets = rtweet::search_tweets(\n    'TPP11 Chile -filter:quote -filter:replies',\n    n = 1000,\n    include_rts = FALSE,\n    retryonratelimit = TRUE\n  )\n  # let's save the tibble just in case and write a csv ommiting list cols\n  saveRDS(tweets, tbl_file)\n  tweets = tweets[, sapply(tweets, class) != 'list'] |> as.data.frame()\n  write.csv(tweets, tweets_file, row.names = FALSE)\n}\n\n\n\n\n\n\n\n\n\n\n## ----r------------------------------------------------------------------------\nis_link = function (x) grepl('^[[:lower:]]+://.+', x)\nis_hashtag = function (x) grepl('^#.+', x)\nis_mention = function (x) grepl('^@.+', x)\nis_number = function (x) grepl('^[[:digit:]]+$', x)\n\n\n\n\n\n\n\n\n\n\n## ----r------------------------------------------------------------------------\nextract_words = function (x) {\n  x = x[!is_link(x)]\n  x = x[!is_hashtag(x)]\n  x = x[!is_mention(x)]\n  x = x[!is_number(x)]\n  x = lapply(x, gsub, pattern = '[^[:alnum:]]', replacement = '') |> unlist()\n  x = x[x != '']\n  tolower(x)\n}\n\n\n\n\n## ----r------------------------------------------------------------------------\nclean_tweets = tweets[['full_text']] |>\n  strsplit(split = '[[:space:]+]') |>\n  lapply(extract_words)\n\nwords = lapply(clean_tweets, function (x) {\n  n = nchar(x)\n  x[n >= 5 & n <= 10]\n})\n\nword_bag = unlist(words)\n\n\n\n\n## ----r------------------------------------------------------------------------\nword_bag = local({\n  query = c('tpp11', 'chile')\n  word_bag[!(word_bag %in% query)]\n})\n\n\n## ----r------------------------------------------------------------------------\nlibrary('wordcloud2')\nlibrary('wesanderson')\n\nwf = local({\n  wb = table(word_bag)\n  word = names(wb)\n  freq = as.numeric(wb)\n  data.frame(word, freq)[freq >= 10, ]\n})\n\n# Nice colors from 'The Darjeeling Express'\nclrs = rep(wesanderson::wes_palette('Darjeeling1', 5), length.out = nrow(wf))\n\nwordcloud2::wordcloud2(wf,\n  background = 'transparent',\n  color = clrs)\n```\n:::\n\n\n[wordcloud2]: https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html\n[tpp11]: https://en.wikipedia.org/wiki/Comprehensive_and_Progressive_Agreement_for_Trans-Pacific_Partnership\n[twitterAPI]: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjiqurGgOj6AhWdDLkGHfjBBRcQFnoECA8QAQ&url=https%3A%2F%2Fdeveloper.twitter.com%2Fen%2Fdocs%2Ftwitter-api&usg=AOvVaw07KoWHf5ew9enXbRwVd6eq\n[rtweet]: https://github.com/ropensci/rtweet\n[wesanderson]: https://github.com/karthik/wesanderson\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<link href=\"../../../site_libs/wordcloud2-0.0.1/wordcloud.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/wordcloud2-0.0.1/wordcloud2-all.js\"></script>\n<script src=\"../../../site_libs/wordcloud2-0.0.1/hover.js\"></script>\n<script src=\"../../../site_libs/wordcloud2-binding-0.2.1/wordcloud2.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}